from typing import Tuple, Union, Callable
from functools import partial

import jax
import jax.numpy as jnp
import numpy as np
from jax import jit, vmap

from ops import pearsonr, spearmanr, zscore, robust_zscore, rank, regbeta, skew, kurtosis


# internal functions
@partial(jit, static_argnums=(1, 2, ))
def _pad_nan_to_front(x: jnp.DeviceArray, pad_size: int, axis=-1):
    """
    pad NaN of `pad_size` along `axis` to the front of the input tensor `x`.
    When rolling along some given `axis` with given window size, we have to pad in front
    of the input to keep the outputs and the inputs sharing the same shapes.
    """
    pad_width = [(0, 0)] * len(x.shape)
    pad_width[axis] = (pad_size, 0)
    o = jnp.pad(x, pad_width=pad_width, mode="constant", constant_values=float('nan'))
    return o
    # pad_value = float('nan')
    # shape = list(x.shape)
    # shape[axis] = pad_size
    # padding = jnp.zeros(shape) + pad_value
    # return jnp.concatenate([padding, x], axis=axis)


# @lru_cache(maxsize=256)
# @partial(jit, static_argnums=(1, 2))
def _gen_unfold_index(rolling_length: int, window: int):
    """This is a low-level func to be called frequently by high-level rolling operation.
    This function generate a 2d index to be applied on rolling axis. The index is in shape (`rolling_length`, `window`).
    `rolling_length` is the size of the rolling axis.
    Indexing `x` with it on `axis` will generate an expanded dimension `axis`+1.
    Thus all the rolling windows are on the expanded dimension.
    Then whatever predefined functions (rank, skew, kurtosis, ic, rank_ic) can be applied on the expanded dimension.
    By doing so, we accelerate the rolling evaluation by implementing vectorization. While the cost is, this incurs
    `window` times memory comsumption due to the expanding.
    """

    idx_unfold = jnp.arange(rolling_length - window + 1)[:, None] + jnp.arange(window)[None, :]
    return idx_unfold

# def _gen_unfold_index(axis_dim: int, window: int):
#     """This is a low-level func to be called frequently by high-level rolling operation.
#     This function generate a 2d index to be applied on rolling axis. The index is in shape (`rolling_length`, `window`).
#     `rolling_length` is the size of the rolling axis.
#     Indexing `x` with it on `axis` will generate an expanded dimension `axis`+1.
#     Thus all the rolling windows are on the expanded dimension.
#     Then whatever predefined functions (rank, skew, kurtosis, ic, rank_ic) can be applied on the expanded dimension.
#     By doing so, we accelerate the rolling evaluation by implementing vectorization. While the cost is, this incurs
#     `window` times memory comsumption due to the expanding.
#     """

#     idx_unfold = jnp.arange(axis_dim)[:, None] + jnp.arange(window)[None, :]
#     return idx_unfold

def _rolling1(
    x: jnp.DeviceArray,
    axis: int,
    window: int,
    func: Callable,
    n_split: int = 1
) -> jnp.DeviceArray:
    """
    Rolling always along the first axis and apply `func` on each expanded window axis.
    The implementation is based on `unfolded` indices generated by `jnp.DeviceArray.unfold`,
    instead of using naive for loop. This brings huge acceleration due to the
    parallelized computations in one go for all possible windows,
    while at the same time incurs `window`-times of memory usuage.
    This function is not supposed to be called directly.
    Parameters
    ----------
    x : jnp.DeviceArray to be unrolled.
    window : int
        size of the rolling window.
    func: Callable
        function to be called on the window.
    """
    step = 1
    pad_size = window - step

    # always assume that the last dimension is splitable, i.e. not involving time rolling.
    split_indices = jnp.array_split(jnp.arange(x.shape[-1]), n_split)

    # unfold and pad
    unfold_2d_idx = _gen_unfold_index(x.shape[axis] + window - 1, window=window)
    if axis < 0:
        axis = axis + x.ndim

    idx_str = ":, " * axis
    res_list = []
    for split_id, split_index in enumerate(split_indices):
        # get x_split with proper front elements, padding when necessary.
        x_split = x[..., split_index] #eval(f"x[{idx_str} split_index]")
        x_split = _pad_nan_to_front(x_split, pad_size=pad_size, axis=axis)

        o = func(eval(f"x_split[{idx_str} unfold_2d_idx]"))#.block_until_ready()
        res_list.append(o)

    res = jnp.concatenate(res_list, axis=-1)
    return res


def _rolling2(
    x: jnp.DeviceArray,
    y: jnp.DeviceArray,
    axis: int,
    window: int,
    func: Callable,
    n_split: int = 1
) -> jnp.DeviceArray:
    """
    Rolling always along the first axis and apply `func` on each expanded window axis.
    The implementation is based on `unfolded` indices generated by `jnp.DeviceArray.unfold`,
    instead of using naive for loop. This brings huge acceleration due to the
    parallelized computations in one go for all possible windows,
    while at the same time incurs `window`-times of memory usuage.
    This function is not supposed to be called directly.
    Parameters
    ----------
    x : jnp.DeviceArray to be unrolled.
    y : jnp.DeviceArray to be unrolled.
    window : int
        size of the rolling window.
    func: Callable
        function to be called on the window.
    """
    step = 1
    pad_size = window - step

    split_indices = jnp.array_split(jnp.arange(x.shape[-1]), n_split)
    # unfold and pad
    unfold_2d_idx = _gen_unfold_index(x.shape[axis] + window - 1, window=window)
    if axis < 0:
        axis = axis + x.ndim

    idx_str = ":, " * axis
    res_list = []
    for split_id, split_index in enumerate(split_indices):
        # get x_split with proper front elements, padding when necessary.
        x_split = x[..., split_index] #eval(f"x[{idx_str} split_index]")
        y_split = y[..., split_index] #eval(f"x[{idx_str} split_index]")
        x_split = _pad_nan_to_front(x_split, pad_size=pad_size, axis=axis)
        y_split = _pad_nan_to_front(y_split, pad_size=pad_size, axis=axis)

        x_ = eval(f"x_split[{idx_str} unfold_2d_idx]")
        y_ = eval(f"y_split[{idx_str} unfold_2d_idx]")
        o = func(x_, y_)#.block_until_ready()
        res_list.append(o)

    res = jnp.concatenate(res_list, axis=-1)
    return res

# def _rolling2(
#     x: jnp.DeviceArray,
#     y: jnp.DeviceArray,
#     axis: int,
#     window: int,
#     func: Callable,
#     n_split: int = 1
# ) -> jnp.DeviceArray:
#     """
#     Same as above function `_rolling1`, except for taking two inputs x, y.
#     """
#     step = 1
#     pad_size = window - step
#     x = _pad_nan_to_front(x, pad_size=pad_size, axis=axis)
#     y = _pad_nan_to_front(y, pad_size=pad_size, axis=axis)

#     unfold_index = _gen_unfold_index(x.shape[axis], window=window)
#     split_unfold_indices = jnp.array_split(unfold_index, n_split, axis=0)
#     if axis < 0:
#         axis = axis + x.ndim

#     idx_str = ":, " * axis
#     res_list = []
#     for split_index in split_unfold_indices:
#         # print(f"x[{idx_str} {split_index}]")
#         # print(f"y[{idx_str} {split_index}]")
#         o = func(
#             eval(f"x[{idx_str} split_index]"),
#             eval(f"y[{idx_str} split_index]"))
#         res_list.append(o)

#     res = jnp.concatenate(res_list, axis=axis)
#     return res


# Rolling Operations
def rolling_corr(
    x: jnp.DeviceArray, y: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    """rolling on dim=0, so func is applied on expanded dim=1."""
    return _rolling2(
        x, y, axis=axis, window=window,
        func=partial(pearsonr, axis=axis+1),
        n_split=n_split)


def rolling_rank_corr(
    x: jnp.DeviceArray, y: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    """rolling on dim=0, so func is applied on expanded dim=1."""
    return _rolling2(
        x, y, axis=axis, window=window,
        func=partial(spearmanr, axis=axis+1),
        n_split=n_split)


# @partial(jit, static_argnums=(1,))
def rolling_mean(
    x: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    """i.e. simple moving average."""
    return _rolling1(
        x, axis=axis, window=window,
        func=lambda x_unrolled: jnp.nanmean(x_unrolled, axis=axis+1, keepdims=False),
        n_split=n_split
    )


sma = rolling_mean


def _nan_wsn_1d(x: jnp.DeviceArray, w: jnp.DeviceArray):
    """Weighted sum of input `x` with normalization. Both input x and weight w are 1d array. The most important
    thing to implement this function is to consider possible NaNs in x.
    """
    nan_idx = jnp.logical_or(jnp.isnan(x), jnp.isnan(w))
    # replace NaNs with 0s.
    x = jnp.where(nan_idx, 0.0, x)
    w = jnp.where(nan_idx, 0.0, w)
    o = jnp.sum(w * x) / jnp.sum(w)  # No NaNs or infs are allowed here.
    return o


@partial(jit, static_argnums=(1, 2))
def _nan_exp_wsn(x: jnp.DeviceArray, axis: int, alpha: float):
    """vectorized exponentially weighted sum with normalizaiton of `x` along `axis`. `x` is ndarray."""
    e = jnp.arange(x.shape[axis]-1, -1, -1)
    w = (1 - alpha) ** e
    return jnp.apply_along_axis(lambda x_1d: _nan_wsn_1d(x_1d, w), axis, x)


def ema(
    x: jnp.DeviceArray, axis: int, window: int, alpha: float = 0.5, n_split: int = 1
) -> jnp.DeviceArray:
    return _rolling1(
        x, axis=axis, window=window,
        func=lambda x_unrolled: _nan_exp_wsn(x_unrolled, axis=axis+1, alpha=alpha),
        n_split=n_split)

# # 2d x and w on axis=1:  (a, b), (b) -> (a)
# _nan_2dwma_axis1 = vmap(_nan_weighted_sum_and_normalize_1d, (0, None), 0)

# # 3d x and w on axis=1: (a, b, c), (b) -> (a, c)
# _nan_3dwma_axis1 = vmap(_nan_2dwma_axis1, (2, None), 1)

# # 4d x and w on axis=1: (a, b, c, d), (b) -> (a, c, d)
# _nan_4dwma_axis1 = vmap(_nan_3dwma_axis1, (3, None), 2)


# @partial(jit, static_argnums=(1, 2, ))
# def ema(x: jnp.DeviceArray, window: int, alpha: float = 0.5) -> jnp.DeviceArray:
#     """Exponentially weighted moving average (only in the window). Given the elements [] in
#     an expanded window, this function computes:

#     \frac{}{}
#     When alpha approaches to 1, ema(x) approaches to x."""
#     e = jnp.arange(window-1, -1, -1)
#     w = (1 - alpha) ** e

#     if len(x.shape) == 3:
#         func = _nan_4dwma_axis1  # for x in shape (date, minute, symbol) and rolling on date
#     elif len(x.shape) == 2:
#         func = _nan_3dwma_axis1  # for x in shape (date*minute, symbol) and rolling on minute
#     elif len(x.shape) == 1:
#         func = _nan_2dwma_axis1  # for x in shape (time,), e.g. time series of some future.
#     else:
#         raise ValueError(f"x shape {x.shape} not supported so far.")

#     return _rolling1(
#         x, window=window,
#         func=lambda x_unrolled: func(x_unrolled, w)
#     )

# @partial(jit, static_argnums=(1, 2))
# def _nanstd(x: jnp.DeviceArray, axis: int = -1, keepdims: bool = False):
#     return jnp.nanstd(x, axis=axis, keepdims=keepdims)

def rolling_std(
    x: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    return _rolling1(
        x, axis=axis, window=window,
        func=lambda x_unrolled: jnp.nanstd(x_unrolled, axis=axis+1, keepdims=False),
        n_split=n_split
    )


def rolling_var(
    x: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    return _rolling1(
        x, axis=axis, window=window,
        func=lambda x_unrolled: jnp.nanvar(x_unrolled, axis=axis+1, keepdims=False),
        n_split=n_split
    )


def rolling_min(
    x: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    return _rolling1(
        x, axis=axis, window=window,
        func=lambda x_unrolled: jnp.nanmin(x_unrolled, axis=axis+1, keepdims=False),
        n_split=n_split)


def rolling_max(
    x: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    return _rolling1(
        x, axis=axis, window=window,
        func=lambda x_unrolled: jnp.nanmax(x_unrolled, axis=axis+1, keepdims=False),
        n_split=n_split)

# def rolling_zscore(
#     x: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
# ) -> jnp.DeviceArray:
#     return _rolling1(
#         x, axis=axis, window=window,
#         func=lambda x_unrolled: zscore(x_unrolled, axis=axis+1),
#         n_split=n_split)

def rolling_robust_zscore(
    x: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    def get_last_rz(x_unrolled, axis: int):
        """return last element after robust_zscore along `axis`."""
        z = robust_zscore(x_unrolled, axis=axis)
        idx_str = ":, " * axis
        last_z = eval(f"z[{idx_str} -1]")
        return last_z

    return _rolling1(
        x, axis=axis, window=window,
        func=partial(get_last_rz, axis=axis+1),
        n_split=n_split)

def rolling_zscore(
    x: jnp.DeviceArray, axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    def get_last_z(x_unrolled, axis: int):
        """return last element after zscore along `axis`."""
        z = zscore(x_unrolled, axis=axis)
        idx_str = ":, " * axis
        last_z = eval(f"z[{idx_str} -1]")
        return last_z

    return _rolling1(
        x, axis=axis, window=window,
        func=partial(get_last_z, axis=axis+1),
        n_split=n_split)


def rolling_regbeta(
    x: jnp.DeviceArray, y: jnp.DeviceArray,
    axis: int, window: int, n_split: int = 1
) -> jnp.DeviceArray:
    return _rolling2(
        x, y, axis=axis, window=window,
        func=partial(regbeta, axis=axis+1),
        n_split=n_split)


def rolling_skew(
    x: jnp.DeviceArray, axis: int, window: int, bias=True, n_split: int = 1
) -> jnp.DeviceArray:
    return _rolling1(
        x, axis=axis, window=window,
        func=partial(skew, axis=axis+1, bias=bias),
        n_split=n_split)

def rolling_kurtosis(
    x: jnp.DeviceArray, axis: int, window: int, bias=True, n_split: int = 1
) -> jnp.DeviceArray:
    return _rolling1(
        x, axis=axis, window=window,
        func=partial(kurtosis, axis=axis+1, bias=bias),
        n_split=n_split)